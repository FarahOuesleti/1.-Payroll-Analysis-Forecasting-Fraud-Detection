{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8438569,"sourceType":"datasetVersion","datasetId":5026590},{"sourceId":8505135,"sourceType":"datasetVersion","datasetId":5076431},{"sourceId":8539960,"sourceType":"datasetVersion","datasetId":5101688},{"sourceId":8603309,"sourceType":"datasetVersion","datasetId":5147691},{"sourceId":8604042,"sourceType":"datasetVersion","datasetId":5148236},{"sourceId":8642826,"sourceType":"datasetVersion","datasetId":5176260}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train Adapt-LLM on few examples","metadata":{}},{"cell_type":"code","source":"#pip install peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%pip uninstall peft -y\n#%pip install git+https://github.com/huggingface/peft\n#%pip install git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T23:27:57.218609Z","iopub.execute_input":"2024-06-08T23:27:57.219176Z","iopub.status.idle":"2024-06-08T23:27:57.223786Z","shell.execute_reply.started":"2024-06-08T23:27:57.219146Z","shell.execute_reply":"2024-06-08T23:27:57.222817Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":" !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:15:09.372898Z","iopub.execute_input":"2024-06-08T21:15:09.373181Z","iopub.status.idle":"2024-06-08T21:15:10.316278Z","shell.execute_reply.started":"2024-06-08T21:15:09.373156Z","shell.execute_reply":"2024-06-08T21:15:10.314949Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#%pip install git+https://github.com/huggingface/peft\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install -U accelerate\n%pip install -U trl \n#%pip install https://pypi.org/simple/ bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, BitsAndBytesConfig,HfArgumentParser,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch, wandb\nfrom datasets import DatasetDict\nfrom trl import SFTTrainer\nimport accelerate\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:15.099043Z","iopub.execute_input":"2024-06-04T13:19:15.100180Z","iopub.status.idle":"2024-06-04T13:19:24.863880Z","shell.execute_reply.started":"2024-06-04T13:19:15.100140Z","shell.execute_reply":"2024-06-04T13:19:24.863094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:15:20.903907Z","iopub.execute_input":"2024-06-08T21:15:20.904287Z","iopub.status.idle":"2024-06-08T21:15:21.275013Z","shell.execute_reply.started":"2024-06-08T21:15:20.904247Z","shell.execute_reply":"2024-06-08T21:15:21.274256Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = \"AdaptLLM/finance-chat\"\n\n# Load base model\nbnb_config = BitsAndBytesConfig(  \n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False,\n)\nmodel_upd = AutoModelForCausalLM.from_pretrained(\n        model,\n        quantization_config=bnb_config,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n)\nmodel_upd.config.use_cache = False # silence the warnings. Please re-enable for inference!\nmodel_upd.config.pretraining_tp = 1\nmodel_upd.gradient_checkpointing_enable()\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:24.873730Z","iopub.execute_input":"2024-06-04T13:19:24.874039Z","iopub.status.idle":"2024-06-04T13:19:32.705786Z","shell.execute_reply.started":"2024-06-04T13:19:24.874015Z","shell.execute_reply":"2024-06-04T13:19:32.703759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Adding the adapters in the layers\nmodel_upd = prepare_model_for_kbit_training(model_upd)\npeft_config = LoraConfig(\n    lora_alpha=512,\n    lora_dropout=0.1,\n    r=512,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel_upd = get_peft_model(model_upd, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:32.706840Z","iopub.status.idle":"2024-06-04T13:19:32.707313Z","shell.execute_reply.started":"2024-06-04T13:19:32.707080Z","shell.execute_reply":"2024-06-04T13:19:32.707099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=90,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=425,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:32.708286Z","iopub.status.idle":"2024-06-04T13:19:32.708700Z","shell.execute_reply.started":"2024-06-04T13:19:32.708484Z","shell.execute_reply":"2024-06-04T13:19:32.708502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\nprint(print_number_of_trainable_model_parameters(model_upd))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:32.709752Z","iopub.status.idle":"2024-06-04T13:19:32.710185Z","shell.execute_reply.started":"2024-06-04T13:19:32.709968Z","shell.execute_reply":"2024-06-04T13:19:32.709986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"## GHOST\n\ndata=pd.read_csv(\"/kaggle/input/gh-latest-update-an/Fraud_ghost_full_91_anonym.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/gh-latest-update-an/Fraud_ghost_test_full_24_anonym.csv\")\n\n#data = data.drop(data.columns[0], axis=1)\n#test_data = test_data.drop(test_data.columns[0], axis=1)\n\njson_data = data.to_json(orient='records')\njson_test_data = test_data.to_json(orient='records')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:14.074925Z","iopub.execute_input":"2024-06-08T21:18:14.075721Z","iopub.status.idle":"2024-06-08T21:18:14.098183Z","shell.execute_reply.started":"2024-06-08T21:18:14.075689Z","shell.execute_reply":"2024-06-08T21:18:14.097338Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"## Misclassification\n'''\ndata=pd.read_csv(\"/kaggle/input/misclasss/New_train_M.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/misclasss/New_test_M.csv.csv\")\n\n#data = data.drop(data.columns[0], axis=1)\n#test_data = test_data.drop(test_data.columns[0], axis=1)\n\njson_data = data.to_json(orient='records')\njson_test_data = test_data.to_json(orient='records')\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Timesheet\n\n# data=pd.read_csv(\"/kaggle/input/timesheet/Timesheet_100_input_anonym.csv\")\n# test_data=pd.read_csv(\"/kaggle/input/timesheet/Timesheet_test_30_anonym.csv\")\n\n# #data = data.drop(data.columns[0], axis=1)\n# #test_data = test_data.drop(test_data.columns[0], axis=1)\n\n# json_data = data.to_json(orient='records')\n# json_test_data = test_data.to_json(orient='records')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L=json_data.split('},{')\nL_test = json_test_data.split('},{')\n\nL[0]=L[0][2:]\nL[-1]=L[-1][:-2]\n\nL_test[0]=L_test[0][2:]\nL_test[-1]=L_test[-1][:-2]\n\nlen(L)\n#len(L_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:17.281120Z","iopub.execute_input":"2024-06-08T21:18:17.282000Z","iopub.status.idle":"2024-06-08T21:18:17.289444Z","shell.execute_reply.started":"2024-06-08T21:18:17.281963Z","shell.execute_reply":"2024-06-08T21:18:17.288531Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"90"},"metadata":{}}]},{"cell_type":"code","source":"def formatList(L):\n    L_res=[]\n    i=0\n\n    while i < len(L) : \n        strr=\"{ \" + L[i] + \" },\"\n        j=i+1\n        while (j< len(L)) and (L[i].split(\",\")[0]== L[j].split(\",\")[0]): \n            strr+= \"{ \" + L[j].split('\"Explanation\":')[0] + \" },\"\n            j+=1\n           \n        L_res.append(strr + ' \"Explanation\":' + L[j-1].split('\"Explanation\":')[1])\n        print(len(L_res))\n        i=j\n        \n    return L_res","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:17.738029Z","iopub.execute_input":"2024-06-08T21:18:17.738413Z","iopub.status.idle":"2024-06-08T21:18:17.745223Z","shell.execute_reply.started":"2024-06-08T21:18:17.738383Z","shell.execute_reply":"2024-06-08T21:18:17.744264Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"L_format = formatList(L)\nL_test_format = formatList(L_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:18.266167Z","iopub.execute_input":"2024-06-08T21:18:18.266556Z","iopub.status.idle":"2024-06-08T21:18:18.272108Z","shell.execute_reply.started":"2024-06-08T21:18:18.266529Z","shell.execute_reply":"2024-06-08T21:18:18.271152Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n1\n2\n3\n4\n5\n6\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(len(L_format)) : \n    Scenario = L_format[i].split('\"Explanation\":\"')\n    L_format[i]= Scenario[0] + '\\n \"Explanation\":\"' + Scenario[1]\n\nfor i in range(len(L_test_format)) : \n    Scenario = L_test_format[i].split('\"Explanation\":\"')\n    L_test_format[i]= Scenario[0] + '\\n \"Explanation\":\"' + Scenario[1]\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:18.780610Z","iopub.execute_input":"2024-06-08T21:18:18.781187Z","iopub.status.idle":"2024-06-08T21:18:18.786486Z","shell.execute_reply.started":"2024-06-08T21:18:18.781157Z","shell.execute_reply":"2024-06-08T21:18:18.785599Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(L_format)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:19.457379Z","iopub.execute_input":"2024-06-08T21:18:19.457960Z","iopub.status.idle":"2024-06-08T21:18:19.463246Z","shell.execute_reply.started":"2024-06-08T21:18:19.457931Z","shell.execute_reply":"2024-06-08T21:18:19.462442Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"code","source":"len(L_test_format)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:18:20.097835Z","iopub.execute_input":"2024-06-08T21:18:20.098721Z","iopub.status.idle":"2024-06-08T21:18:20.104094Z","shell.execute_reply.started":"2024-06-08T21:18:20.098689Z","shell.execute_reply":"2024-06-08T21:18:20.103158Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"6"},"metadata":{}}]},{"cell_type":"code","source":"# Timesheet\n\n# for i in range(len(L_format)) : \n#     L_format[i]=\"Generate a Timesheet Fraud Scenario : { \" + L_format[i] + \" },\"\n\n# for i in range(len(L_test_format)) : \n#     L_test_format[i]=\"Generate a Timesheet Fraud Scenario : { \" + L_test_format[i] + \" },\"\n    \n# L_test_format[-1]\n# L_format[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GHOST\n\n\nfor i in range(len(L_format)) : \n    L_format[i]=\"Generate a Ghost Worker Fraud Scenario : { \" + L_format[i] + \" },\"\n\nfor i in range(len(L_test_format)) : \n    L_test_format[i]=\"Generate a Ghost Worker Fraud Scenario : { \" + L_test_format[i] + \" },\"\n    \nL_test_format[2]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Misclassification\n\n'''\nfor i in range(len(L_format)) : \n    L_format[i]=\"Generate a Misclassification Fraud Scenario : { \" + L_format[i] + \" },\"\n\nfor i in range(len(L_test_format)) : \n    L_test_format[i]=\"Generate a Misclassification Fraud Scenario : { \" + L_test_format[i] + \" },\"\n    \nL_test_format[2]\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare data format","metadata":{}},{"cell_type":"code","source":"import pyarrow as pa\nimport pyarrow.dataset as ds\nimport pandas as pd\nfrom datasets import Dataset\n\n#dataset = ds.dataset(pa.Table.from_pandas(data).to_batches())\n\n### convert to Huggingface dataset\n#hg_dataset = Dataset(pa.Table.from_pandas(data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = pd.DataFrame(L_format)\ndataset = ds.dataset(pa.Table.from_pandas(d).to_batches())\n### convert to Huggingface dataset\nhg_dataset = Dataset(pa.Table.from_pandas(d))\n\ntest_d = pd.DataFrame(L_test_format)\ntest_dataset = ds.dataset(pa.Table.from_pandas(test_d).to_batches())\n### convert to Huggingface dataset\ntest_hg_dataset = Dataset(pa.Table.from_pandas(test_d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_hg_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hg_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"'''\nfrom transformers import EarlyStoppingCallback\n\n# Define early stopping parameters\nearly_stopping_callback = EarlyStoppingCallback(\n    early_stopping_patience=3,  # Number of evaluations with no improvement before stopping\n    load_best_model_at_end = True\n)\n\ntraining_arguments.evaluation_strategy = \"steps\"\ntraining_arguments.eval_steps = 25  \n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model_upd,\n    train_dataset=hg_dataset,\n    eval_dataset=test_hg_dataset,\n    peft_config=peft_config,\n    max_seq_length= None,\n    dataset_text_field=\"0\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,  \n    #callbacks=[early_stopping_callback],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='5ecd16230ada8cfbb0afc08d9a978ba0593ad51f')\n\n# Initialize a new wandb run\nwandb.init(project=\"adapt-ghost-1\", name=\"run-7\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import torch\n#torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_output = trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"____________________________________\n# Notes\n\ninclude in a RAG file :\n- How the attributes values are calculated\n- Baseline logic for how posts should be given based on seniority (rule style)\n- information about what year we currently in (reference)","metadata":{}},{"cell_type":"markdown","source":"## Pushing model to huggingface","metadata":{}},{"cell_type":"code","source":"#access token\nhg_token= \"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\"\nimport huggingface_hub\nhuggingface_hub.login(hg_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('adapt-llm-ghost-Fr-90xr512-2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_upd.push_to_hub(\"adapt-llm-Misc-Fr\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from huggingface_hub import login\n#login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi, create_repo\napi = HfApi()\n\napi.create_repo(repo_id=\"adapt-llm-ghost-Fr-90xr512-2\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"api.upload_folder(    \n    folder_path=\"./adapt-llm-ghost-Fr-90xr512-2\",\n    repo_id=\"FO-UA/adapt-llm-ghost-Fr-90xr512-2\",\n    repo_type=\"model\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}