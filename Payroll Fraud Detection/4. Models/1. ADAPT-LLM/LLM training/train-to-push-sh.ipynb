{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":8611433,"sourceType":"datasetVersion","datasetId":5153456},{"sourceId":8642839,"sourceType":"datasetVersion","datasetId":5176268}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train Adapt-LLM on few examples","metadata":{}},{"cell_type":"code","source":"#pip install peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%pip uninstall peft -y\n#%pip install git+https://github.com/huggingface/peft\n#%pip install git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:52:05.765687Z","iopub.execute_input":"2024-06-08T21:52:05.766247Z","iopub.status.idle":"2024-06-08T21:52:08.151830Z","shell.execute_reply.started":"2024-06-08T21:52:05.766221Z","shell.execute_reply":"2024-06-08T21:52:08.150724Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#%pip install git+https://github.com/huggingface/peft\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install -U accelerate\n%pip install -U trl \n#%pip install https://pypi.org/simple/ bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, BitsAndBytesConfig,HfArgumentParser,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch, wandb\nfrom datasets import DatasetDict\nfrom trl import SFTTrainer, SFTConfig\nimport accelerate\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:15.099043Z","iopub.execute_input":"2024-06-04T13:19:15.100180Z","iopub.status.idle":"2024-06-04T13:19:24.863880Z","shell.execute_reply.started":"2024-06-04T13:19:15.100140Z","shell.execute_reply":"2024-06-04T13:19:24.863094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = \"AdaptLLM/finance-chat\"\n\n# Load base model\nbnb_config = BitsAndBytesConfig(  \n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False,\n)\nmodel_upd = AutoModelForCausalLM.from_pretrained(\n        model,\n        quantization_config=bnb_config,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n)\nmodel_upd.config.use_cache = False # silence the warnings. Please re-enable for inference!\nmodel_upd.config.pretraining_tp = 1\nmodel_upd.gradient_checkpointing_enable()\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:24.873730Z","iopub.execute_input":"2024-06-04T13:19:24.874039Z","iopub.status.idle":"2024-06-04T13:19:32.705786Z","shell.execute_reply.started":"2024-06-04T13:19:24.874015Z","shell.execute_reply":"2024-06-04T13:19:32.703759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Adding the adapters in the layers\nmodel_upd = prepare_model_for_kbit_training(model_upd)\npeft_config = LoraConfig(\n    lora_alpha=512,\n    lora_dropout=0.1,\n    r=512,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel_upd = get_peft_model(model_upd, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:32.706840Z","iopub.status.idle":"2024-06-04T13:19:32.707313Z","shell.execute_reply.started":"2024-06-04T13:19:32.707080Z","shell.execute_reply":"2024-06-04T13:19:32.707099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = SFTConfig(\n    output_dir=\"./results\",\n    num_train_epochs=170, #100 #40\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=425 ,#840,#600 #240,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:32.708286Z","iopub.status.idle":"2024-06-04T13:19:32.708700Z","shell.execute_reply.started":"2024-06-04T13:19:32.708484Z","shell.execute_reply":"2024-06-04T13:19:32.708502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\nprint(print_number_of_trainable_model_parameters(model_upd))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:32.709752Z","iopub.status.idle":"2024-06-04T13:19:32.710185Z","shell.execute_reply.started":"2024-06-04T13:19:32.709968Z","shell.execute_reply":"2024-06-04T13:19:32.709986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"## GHOST\n'''\ndata=pd.read_csv(\"/kaggle/input/update-gh/Fraud_Ghost_end.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/ghossttt/Test_Fraud_Ghost_end.csv\")\n\n#data = data.drop(data.columns[0], axis=1)\n#test_data = test_data.drop(test_data.columns[0], axis=1)\n\njson_data = data.to_json(orient='records')\njson_test_data = test_data.to_json(orient='records')\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Misclassification\n'''\ndata=pd.read_csv(\"/kaggle/input/misclasss/New_train_M.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/misclasss/New_test_M.csv.csv\")\n\n#data = data.drop(data.columns[0], axis=1)\n#test_data = test_data.drop(test_data.columns[0], axis=1)\nrch\njson_data = data.to_json(orient='records')\njson_test_data = test_data.to_json(orient='records')\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Timesheet\n\ndata=pd.read_csv(\"/kaggle/input/latest-upd-tsh/Timesheet_100_input_anonym.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/latest-upd-tsh/Timesheet_test_30_anonym.csv\")\n\n#data = data.drop(data.columns[0], axis=1)\n#test_data = test_data.drop(test_data.columns[0], axis=1)\n\njson_data = data.to_json(orient='records')\njson_test_data = test_data.to_json(orient='records')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:52:08.153491Z","iopub.execute_input":"2024-06-08T21:52:08.153766Z","iopub.status.idle":"2024-06-08T21:52:08.176767Z","shell.execute_reply.started":"2024-06-08T21:52:08.153739Z","shell.execute_reply":"2024-06-08T21:52:08.175948Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Timesheet\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/latest-upd-tsh/Timesheet_100_input_anonym.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m test_data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/latest-upd-tsh/Timesheet_test_30_anonym.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#data = data.drop(data.columns[0], axis=1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#test_data = test_data.drop(test_data.columns[0], axis=1)\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"],"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error"}]},{"cell_type":"code","source":"L=json_data.split('},{')\nL_test = json_test_data.split('},{')\n\nL[0]=L[0][2:]\nL[-1]=L[-1][:-2]\n\nL_test[0]=L_test[0][2:]\nL_test[-1]=L_test[-1][:-2]\n\nlen(L)\n#len(L_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:52:08.177413Z","iopub.status.idle":"2024-06-08T21:52:08.177710Z","shell.execute_reply.started":"2024-06-08T21:52:08.177563Z","shell.execute_reply":"2024-06-08T21:52:08.177579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def formatList(L):\n    L_res=[]\n    i=0\n\n    while i < len(L) : \n        strr=\"{ \" + L[i] + \" },\"\n        j=i+1\n        while (j< len(L)) and (L[i].split(\",\")[0]== L[j].split(\",\")[0]): \n            strr+= \"{ \" + L[j].split('\"Explanation\":')[0] + \" },\"\n            j+=1\n           \n        L_res.append(strr + ' \"Explanation\":' + L[j-1].split('\"Explanation\":')[1])\n        print(len(L_res))\n        i=j\n        \n    return L_res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L_format = formatList(L)\nL_test_format = formatList(L_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(L_format)) : \n    Scenario = L_format[i].split('\"Explanation\":\"')\n    L_format[i]= Scenario[0] + '\\n \"Explanation\":\"' + Scenario[1]\n\nfor i in range(len(L_test_format)) : \n    Scenario = L_test_format[i].split('\"Explanation\":\"')\n    L_test_format[i]= Scenario[0] + '\\n \"Explanation\":\"' + Scenario[1]\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L_format","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Timesheet\n\nfor i in range(len(L_format)) : \n    L_format[i]=\"Generate a Timesheet Fraud Scenario : { \" + L_format[i] + \" },\"\n\nfor i in range(len(L_test_format)) : \n    L_test_format[i]=\"Generate a Timesheet Fraud Scenario : { \" + L_test_format[i] + \" },\"\n    \nL_test_format[-1]\nL_format[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GHOST\n\n'''\nfor i in range(len(L_format)) : \n    L_format[i]=\"Generate a Ghost Fraud Scenario : { \" + L_format[i] + \" },\"\n\nfor i in range(len(L_test_format)) : \n    L_test_format[i]=\"Generate a Ghost Fraud Scenario : { \" + L_test_format[i] + \" },\"\n    \nL_test_format[2]\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Misclassification\n\n'''\nfor i in range(len(L_format)) : \n    L_format[i]=\"Generate a Misclassification Fraud Scenario : { \" + L_format[i] + \" },\"\n\nfor i in range(len(L_test_format)) : \n    L_test_format[i]=\"Generate a Misclassification Fraud Scenario : { \" + L_test_format[i] + \" },\"\n    \nL_test_format[2]\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare data format","metadata":{}},{"cell_type":"code","source":"import pyarrow as pa\nimport pyarrow.dataset as ds\nimport pandas as pd\nfrom datasets import Dataset\n\n#dataset = ds.dataset(pa.Table.from_pandas(data).to_batches())\n\n### convert to Huggingface dataset\n#hg_dataset = Dataset(pa.Table.from_pandas(data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = pd.DataFrame(L_format)\ndataset = ds.dataset(pa.Table.from_pandas(d).to_batches())\n### convert to Huggingface dataset\nhg_dataset = Dataset(pa.Table.from_pandas(d))\n\ntest_d = pd.DataFrame(L_test_format)\ntest_dataset = ds.dataset(pa.Table.from_pandas(test_d).to_batches())\n### convert to Huggingface dataset\ntest_hg_dataset = Dataset(pa.Table.from_pandas(test_d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_hg_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hg_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"'''\nfrom transformers import EarlyStoppingCallback\n\n# Define early stopping parameters\nearly_stopping_callback = EarlyStoppingCallback(\n    early_stopping_patience=3,  # Number of evaluations with no improvement before stopping\n    load_best_model_at_end = True\n)\n\ntraining_arguments.evaluation_strategy = \"steps\"\ntraining_arguments.eval_steps = 25  \n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model_upd,\n    train_dataset=hg_dataset,\n    eval_dataset=test_hg_dataset,\n    peft_config=peft_config,\n    max_seq_length= None,\n    dataset_text_field=\"0\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='5ecd16230ada8cfbb0afc08d9a978ba0593ad51f')\n\n# Initialize a new wandb run\nwandb.init(project=\"adapt-timesheet-1\", name=\"run-8\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import torch\n#torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_output = trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"____________________________________\n# Notes\n\ninclude in a RAG file :\n- How the attributes values are calculated\n- Baseline logic for how posts should be given based on seniority (rule style)\n- information about what year we currently in (reference)","metadata":{}},{"cell_type":"markdown","source":"## Pushing model to huggingface","metadata":{}},{"cell_type":"code","source":"#access token\nhg_token= \"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\"\nimport huggingface_hub\nhuggingface_hub.login(hg_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('adapt-llm-Timesheet-Fr-170xr512')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_upd.push_to_hub(\"adapt-llm-Misc-Fr\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from huggingface_hub import login\n#login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi, create_repo\napi = HfApi()\n\napi.create_repo(repo_id=\"adapt-llm-Timesheet-Fr-170xr512\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"api.upload_folder(    \n    folder_path=\"./adapt-llm-Timesheet-Fr-170xr512\",\n    repo_id=\"FO-UA/adapt-llm-Timesheet-Fr-170xr512\",\n    repo_type=\"model\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}