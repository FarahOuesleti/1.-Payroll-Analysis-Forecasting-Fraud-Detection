{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8719729,"sourceType":"datasetVersion","datasetId":5232108},{"sourceId":8721285,"sourceType":"datasetVersion","datasetId":5233340}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#%pip install git+https://github.com/huggingface/peft\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install -U accelerate\n%pip install -U trl \n#%pip install https://pypi.org/simple/ bitsandbytes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer ,BitsAndBytesConfig\nimport torch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4bit Nested","metadata":{}},{"cell_type":"code","source":"# %%time\n# bnb_config = BitsAndBytesConfig(  \n#     load_in_4bit=True,\n#     bnb_4bit_quant_type= \"nf4\", # normal float : a new 4bit datatype adapted for weights that have been initialized using a normal distribution. \n#     bnb_4bit_compute_dtype= torch.bfloat16, # Set the computation data type to bfloat16 instead of default float32\n#     bnb_4bit_use_double_quant= True, # Nested quantization : where the quantization constants from the first quantization are quantized again. - no performance lost\n# )\n\n\n# config = PeftConfig.from_pretrained(\"FO-UA/adapt-llm-Misc-Fr-40Xr256Xa512\")\n# model_new = AutoModelForCausalLM.from_pretrained(\"AdaptLLM/finance-chat\", device_map=\"cuda\", quantization_config=bnb_config)\n# model_new = PeftModel.from_pretrained(model_new, \"FO-UA/adapt-llm-Misc-Fr-40Xr256Xa512\") #.to(\"cuda\")\n\n# # Load tokenizer\n# tokenizer = AutoTokenizer.from_pretrained(\"FO-UA/adapt-llm-Misc-Fr-40Xr256Xa512\", trust_remote_code=True)\n# tokenizer.padding_side = 'right'\n# tokenizer.pad_token = tokenizer.eos_token\n# tokenizer.add_eos_token = True\n# tokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4bit + TorchCompile","metadata":{}},{"cell_type":"code","source":"%%time\nbnb_config = BitsAndBytesConfig(  \n    load_in_4bit=True,\n    bnb_4bit_quant_type= \"nf4\", # normal float : a new 4bit datatype adapted for weights that have been initialized using a normal distribution. \n    bnb_4bit_compute_dtype= torch.bfloat16, # Set the computation data type to bfloat16 instead of default float32\n    bnb_4bit_use_double_quant= False, # Nested quantization : where the quantization constants from the first quantization are quantized again. - no performance lost\n)\n\nconfig = PeftConfig.from_pretrained(\"FO-UA/adapt-llm-Misc-Fr-40Xr256Xa512\")\nmodel_new = AutoModelForCausalLM.from_pretrained(\"AdaptLLM/finance-chat\", device_map=\"cuda\", quantization_config=bnb_config)\nmodel_new = PeftModel.from_pretrained(model_new, \"FO-UA/adapt-llm-Misc-Fr-40Xr256Xa512\") #.to(\"cuda\")\nmodel_new_compile = torch.compile(model_new)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"FO-UA/adapt-llm-Misc-Fr-40Xr256Xa512\", trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List input : Input Preparation ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/misclass/New_test_M_anonym.csv\")\n\njson_data = data.to_json(orient='records')\n\nL=json_data.split('},{')\n\nL[0]=L[0][2:]\nL[-1]=L[-1][:-2]\n\n\nfor i in range(len(L)) : \n    L[i]=\" Instruction : Generate a Misclassification Fraud Scenario : \\n Completion : {\" + L[i] + \" }\"\n    \n\ndata_2=pd.read_csv(\"/kaggle/input/misclass/New_train_M_anonym.csv\")\n\njson_data_2 = data_2.to_json(orient='records')\n\nLL=json_data_2.split('},{')\n\nLL[0]=LL[0][2:]\nLL[-1]=LL[-1][:-2]\n\nfor i in range(len(L)) : \n    LL[i]=\" Instruction : Generate a Misclassification Fraud Scenario : \\n Completion : {\" + LL[i] + \" }\"\n    \n    \nL_full = L + LL\nlen(L_full)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T12:33:30.730953Z","iopub.execute_input":"2024-06-18T12:33:30.731352Z","iopub.status.idle":"2024-06-18T12:33:31.232855Z","shell.execute_reply.started":"2024-06-18T12:33:30.731321Z","shell.execute_reply":"2024-06-18T12:33:31.231739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batch function Definition & Generation","metadata":{}},{"cell_type":"markdown","source":"## V1 : Simple","metadata":{}},{"cell_type":"code","source":"# def batch_generation(L) :\n    \n#     L_result=[]\n#     for i in range(len(L)) :\n#         user_input = (f'''{L[i]} \n        \n#             Instruction : Generate a Misclassification Fraud scenario :           \n#             ''' +'''\n            \n#             {\n#             \"PersonID\": \n#             \"Seniority_previous_company(N-2) (in days)\": \n#             \"Contract_in_group_duration (in days)\": \n#             \"Seniority_previous_company(N-1) (in days)\": \n#             \"Seniority_in_Group (in days)\": \n#             \"Contract_Date\": \n#             \"Leave_Date\": \n#             \"Entry_Date_Company_1\": \n#             \"Sex\": \n#             \"Contract Type\": \n#             \"CODENT\": \n#             \"Position\": \n#             \"Classification\": \n#             \"Work_form\": \n#             \"CODSOR\": \n#             \"Original_company\": \n#             \"Leave_Category\": \n#             \"Leave_Reason\": \n#             \"Transfer_Reason\": \n#             \"Transfer_company\": \n#             \"Explanation\": \n#             }\n\n#             Completion :  \n            \n#             ''')\n#         initial_prompt = ''' A Misclassification fraud is a payroll fraud type where the perpetrator misclassifies an employee of an enterprise in order for the employee to get higher or lower pay than what his diploma or seniority should allow him.\n#         Note that the actual year we are currently at is : 2024. \n#         I want it to be in json format.\n       \n#         '''\n\n#         prompt = f\"<s>[INST] <<SYS>>{initial_prompt}<</SYS>>\\n\\n{user_input} [/INST]\"\n\n\n#         inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(model_new.device) #to(\"cuda\") #.to(model_new.device)\n#         outputs =model_new.generate(input_ids=inputs, \n#                              max_new_tokens=2000,  #1200 for 3 examples \n#                              do_sample=True,\n#                              temperature=1.2\n#                             )[0]\n\n#         answer_start = int(inputs.shape[-1])\n#         pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n#         L_result.append(pred)\n        \n#         # save str in file format\n#         print(user_input)\n#         file_name = 'Assis_2_Temp12_Misclass' + str(i) + '.txt'\n#         with open( file_name , 'w') as f:\n#             f.write(pred)\n#         print(f' \\n file {i} saved')\n        \n#         print(pred)\n#         print('\\n ------------------')\n    \n#     return L_result\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## V2","metadata":{}},{"cell_type":"code","source":"def batch_generation(L,modell) :\n    \n    L_result=[]\n    for i in range(len(L)) :\n        user_input = (f'''{L[i]} \n        \n            Instruction : Generate a Misclassification Fraud scenario :           \n            ''' +'''\n            \n            {\n            \"PersonID\": \n            \"Seniority_previous_company(N-2) (in days)\": \n            \"Contract_in_group_duration (in days)\": \n            \"Seniority_previous_company(N-1) (in days)\": \n            \"Seniority_in_Group (in days)\": \n            \"Contract_Date\": \n            \"Leave_Date\": \n            \"Entry_Date_Company_1\": \n            \"Sex\": \n            \"Contract Type\": \n            \"CODENT\": \n            \"Position\": \n            \"Classification\": \n            \"Work_form\": \n            \"CODSOR\": \n            \"Original_company\": \n            \"Leave_Category\": \n            \"Leave_Reason\": \n            \"Transfer_Reason\": \n            \"Transfer_company\": \n            \"Explanation\": \n            }\n\n    Show the generated Fraud scenario, in json format.\n    \n    ''')\n        initial_prompt = ''' A Misclassification fraud is a payroll fraud type where the perpetrator misclassifies an employee of an enterprise in order for the employee to get higher or lower pay than what his diploma or seniority should allow him.\n            Note that the actual year we are currently in is : 2024. \n            I want it to be in json format.\n\n            These are a few things you should note :\n            These are correspondances between values of Position and Classification.\n            Position\tClassification\n            Supervisor\tSupervisor\n            Manager/Director\tExecutive C3\n            Manager/Director\tExecutive C1\n            Assimilated Executive\tAssimilated Executive\n            Higher Executive\tExecutive\n            Employee\tEmployee E1\n            Employee\tEmployee E3\n            Employee\tEmployee E4\n            Manager/Director\tAssimilated Executive\n            Employee\tEmployee E2\n            Executive\tExecutive C2\n\n            The hierarchy of Classification in an ascending order is as follows : \n            Employee E1 - Employee E2 - Employee E3 - Employee E4 - Supervisor - Executive C1 - Executive C2 - Executive C3 - Assimilated Executive\n\n            Transfer Company can take values only from this list : \n            [\"TMG\", \"EUR\", \"ITI\", \"PRO\", \"TWW\", \"SMS\", \"SBS\", \"ITM\", \"IIS\", \"ATX\", \"AFA\"]\n\n            When Transfer_Reason is 'Not Transferred', and Transfer_company is 'UNSPECIFIED', it's because the employee has not been trnasferred, so Transfer_company takes a default value of UNSCPECIFIED.\n\n            Show the generated Fraud scenario, in json format.\n            '''\n\n        prompt = f\"<s>[INST] <<SYS>>{initial_prompt}<</SYS>>\\n\\n{user_input} [/INST]\"\n\n\n        inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(model_new_compile.device) #to(\"cuda\") #.to(model_new.device)\n        outputs =model_new_compile.generate(input_ids=inputs, \n                             max_new_tokens=3000,  #1200 for 3 examples \n                     do_sample=True,\n                     temperature=1.2\n                    )[0]\n\n        answer_start = int(inputs.shape[-1])\n        pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n        L_result.append(pred)\n        \n        # save str in file format\n        print(user_input)\n        file_name = 'Assis_2_Temp12_Misclass' + str(i) + '.txt'\n        with open( file_name , 'w') as f:\n            f.write(pred)\n        print(f' \\n file {i} saved')\n        \n        print(pred)\n        print('\\n ------------------')\n    \n    return L_result\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_generation(L_full,model_new)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_generation(L_full,model_new_compile)","metadata":{},"execution_count":null,"outputs":[]}]}